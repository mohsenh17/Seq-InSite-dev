2023-02-22 10:27:07.496810: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-22 10:27:08.549180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13657 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_MSA_1 (InputLayer)    [(None, 9, 768)]          0         
                                                                 
 flatten (Flatten)           (None, 6912)              0         
                                                                 
 dropout (Dropout)           (None, 6912)              0         
                                                                 
 dense_MSA_1 (Dense)         (None, 256)               1769728   
                                                                 
 dropout_1 (Dropout)         (None, 256)               0         
                                                                 
 dense_MSA_2 (Dense)         (None, 128)               32896     
                                                                 
 dropout_2 (Dropout)         (None, 128)               0         
                                                                 
 dense_MSA_3 (Dense)         (None, 16)                2064      
                                                                 
 dropout_3 (Dropout)         (None, 16)                0         
                                                                 
 dense_MSA_4 (Dense)         (None, 1)                 17        
                                                                 
=================================================================
Total params: 1,804,705
Trainable params: 1,804,705
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100

Epoch 1: val_loss improved from inf to 0.46230, saving model to models/MLP_MSA_L9.h5
2703/2703 - 514s - loss: 0.4893 - acc: 0.8085 - auc: 0.2401 - val_loss: 0.4623 - val_acc: 0.8050 - val_auc: 0.3757 - 514s/epoch - 190ms/step
Epoch 2/100

Epoch 2: val_loss did not improve from 0.46230
2703/2703 - 542s - loss: 0.4595 - acc: 0.8112 - auc: 0.3144 - val_loss: 0.4625 - val_acc: 0.8053 - val_auc: 0.3704 - 542s/epoch - 201ms/step
Epoch 3/100

Epoch 3: val_loss improved from 0.46230 to 0.45340, saving model to models/MLP_MSA_L9.h5
2703/2703 - 545s - loss: 0.4547 - acc: 0.8117 - auc: 0.3276 - val_loss: 0.4534 - val_acc: 0.8055 - val_auc: 0.3816 - 545s/epoch - 202ms/step
Epoch 4/100

Epoch 4: val_loss did not improve from 0.45340
2703/2703 - 320s - loss: 0.4520 - acc: 0.8121 - auc: 0.3361 - val_loss: 0.4607 - val_acc: 0.8052 - val_auc: 0.3650 - 320s/epoch - 118ms/step
Epoch 5/100

Epoch 5: val_loss did not improve from 0.45340
2703/2703 - 510s - loss: 0.4501 - acc: 0.8122 - auc: 0.3413 - val_loss: 0.4582 - val_acc: 0.8053 - val_auc: 0.3808 - 510s/epoch - 189ms/step
Epoch 6/100

Epoch 6: val_loss did not improve from 0.45340
2703/2703 - 527s - loss: 0.4486 - acc: 0.8125 - auc: 0.3458 - val_loss: 0.4539 - val_acc: 0.8058 - val_auc: 0.3910 - 527s/epoch - 195ms/step
Epoch 7/100

Epoch 7: val_loss did not improve from 0.45340
2703/2703 - 401s - loss: 0.4479 - acc: 0.8127 - auc: 0.3482 - val_loss: 0.4538 - val_acc: 0.8053 - val_auc: 0.3682 - 401s/epoch - 148ms/step
Epoch 7: early stopping
2023-02-22 11:23:15.000391: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
